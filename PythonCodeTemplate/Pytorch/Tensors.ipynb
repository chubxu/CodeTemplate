{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 张量\n",
    "张量是一种特殊的数据结构，与数组和矩阵非常相似。在 PyTorch 中，我们使用张量对模型的输入和输出以及模型的参数进行编码。\n",
    "\n",
    "张量类似于 NumPy 的 ndarrays，不同之处在于张量可以在 GPU 或其他硬件加速器上运行。事实上，张量和 NumPy 数组通常可以共享相同的底层内存，从而无需复制数据（请参阅 [Bridge with NumPy](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label)）。张量也针对自动微分进行了优化（我们将在稍后的 [Autograd](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html) 部分中看到更多相关信息）。如果您熟悉 ndarrays，那么您将对 Tensor API 不陌生。如果不熟悉，那么就来学习吧！"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T23:48:43.477731Z",
     "end_time": "2023-04-06T23:49:03.152185Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 初始化一个张量\n",
    "张量可以通过多种方式初始化。下面来看看几个例子：\n",
    "\n",
    "**直接从原始数据初始化**\n",
    "张量可以直接从数据中创建。数据类型是自动推断的。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T23:49:03.155957Z",
     "end_time": "2023-04-06T23:49:03.899167Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**从numpy数组初始化**\n",
    "可以从 NumPy 数组创建张量（反之亦然 - 请参阅 [Bridge with NumPy](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label)）。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T23:49:03.902161Z",
     "end_time": "2023-04-06T23:49:04.133749Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**从其它张量初始化**\n",
    "除非明确覆盖，否则新张量保留参数张量的属性（形状、数据类型）。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.7045, 0.4677],\n",
      "        [0.2551, 0.4118]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T23:49:04.142752Z",
     "end_time": "2023-04-06T23:49:04.924552Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**具有随机值或者常量值**\n",
    "下面的shape是一个指定了张量的元组。在下面的函数中，它决定了输出张量的维度。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.1145, 0.6818, 0.1542],\n",
      "        [0.0803, 0.7747, 0.9535]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3, )\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T23:49:04.926966Z",
     "end_time": "2023-04-06T23:49:04.986145Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 张量属性\n",
    "张量属性描述了张量的维度、数据类型和存储设备"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T23:49:04.941263Z",
     "end_time": "2023-04-06T23:49:04.991164Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 张量的操作\n",
    "[这里](https://pytorch.org/docs/stable/torch.html)全面描述了100多个张量操作，包括算术，线性代数，矩阵操作（转置，索引，切片），采样等。\n",
    "\n",
    "每一个操作都可以在GPU上运行（通常比GPU更快）。如果您使用的是COLAB，请通过 运行时>更改运行时类型>GPU 操作链路分配GPU。\n",
    "\n",
    "默认情况下都在CPU上创建张量。我们需要使用.to方法将张量显式移动到GPU（在检查GPU可用性之后）。请记住，在时间和内存方面，跨设备复制大量张量会非常损耗性能！"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"cuda available\")\n",
    "    tensor = tensor.to(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T23:49:04.959214Z",
     "end_time": "2023-04-06T23:49:05.080888Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "从列表中尝试一些操作。如果您熟悉Numpy API，则会发现使用张量API轻而易举。\n",
    "\n",
    "**标准的numpy型索引和切片**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T23:49:05.081886Z",
     "end_time": "2023-04-06T23:49:05.157510Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T23:49:05.098841Z",
     "end_time": "2023-04-06T23:49:05.163223Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
