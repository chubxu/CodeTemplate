{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 张量\n",
    "张量是一种特殊的数据结构，与数组和矩阵非常相似。在 PyTorch 中，我们使用张量对模型的输入和输出以及模型的参数进行编码。\n",
    "\n",
    "张量类似于 NumPy 的 ndarrays，不同之处在于张量可以在 GPU 或其他硬件加速器上运行。事实上，张量和 NumPy 数组通常可以共享相同的底层内存，从而无需复制数据（请参阅 [Bridge with NumPy](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label)）。张量也针对自动微分进行了优化（我们将在稍后的 [Autograd](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html) 部分中看到更多相关信息）。如果您熟悉 ndarrays，那么您将对 Tensor API 不陌生。如果不熟悉，那么就来学习吧！"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T23:18:01.502204Z",
     "end_time": "2023-04-08T23:18:01.604912Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 初始化一个张量\n",
    "张量可以通过多种方式初始化。下面来看看几个例子：\n",
    "\n",
    "**直接从原始数据初始化**\n",
    "张量可以直接从数据中创建。数据类型是自动推断的。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T23:18:01.514648Z",
     "end_time": "2023-04-08T23:18:01.681711Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**从numpy数组初始化**\n",
    "可以从 NumPy 数组创建张量（反之亦然 - 请参阅 [Bridge with NumPy](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label)）。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T23:18:01.530605Z",
     "end_time": "2023-04-08T23:18:01.682710Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**从其它张量初始化**\n",
    "除非明确覆盖，否则新张量保留参数张量的属性（形状、数据类型）。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.6087, 0.3386],\n",
      "        [0.8160, 0.8963]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T23:18:01.546399Z",
     "end_time": "2023-04-08T23:18:01.684673Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**具有随机值或者常量值**\n",
    "下面的shape是一个指定了张量的元组。在下面的函数中，它决定了输出张量的维度。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.5121, 0.6116, 0.9648],\n",
      "        [0.1209, 0.2535, 0.4767]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3, )\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T23:18:01.562722Z",
     "end_time": "2023-04-08T23:18:01.698635Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 张量属性\n",
    "张量属性描述了张量的维度、数据类型和存储设备"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T23:18:01.577762Z",
     "end_time": "2023-04-08T23:18:01.699661Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 张量的操作\n",
    "[这里](https://pytorch.org/docs/stable/torch.html)全面描述了100多个张量操作，包括算术，线性代数，矩阵操作（转置，索引，切片），采样等。\n",
    "\n",
    "每一个操作都可以在GPU上运行（通常比GPU更快）。如果您使用的是COLAB，请通过 运行时>更改运行时类型>GPU 操作链路分配GPU。\n",
    "\n",
    "默认情况下都在CPU上创建张量。我们需要使用.to方法将张量显式移动到GPU（在检查GPU可用性之后）。请记住，在时间和内存方面，跨设备复制大量张量会非常损耗性能！"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"cuda available\")\n",
    "    tensor = tensor.to(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T23:18:01.594717Z",
     "end_time": "2023-04-08T23:18:01.714625Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "从列表中尝试一些操作。如果您熟悉Numpy API，则会发现使用张量API轻而易举。\n",
    "\n",
    "**标准的numpy型索引和切片**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T23:18:01.609873Z",
     "end_time": "2023-04-08T23:18:01.724564Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**拼接张量**\n",
    "您可以使用 torch.cat 沿给定维度连接一系列张量。另见 [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html)，另外一个张量拼接方法，但与 torch.cat 略有不同。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T23:18:01.624832Z",
     "end_time": "2023-04-08T23:18:01.724564Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**算数运算**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1:tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "y2:tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "y3:tensor([[5.4285e-01, 4.2646e-01, 1.8945e-01, 2.9056e-01],\n",
      "        [3.9075e-01, 1.7919e-01, 2.8425e-01, 2.0635e-01],\n",
      "        [7.1765e-02, 6.7266e-01, 6.1798e-04, 2.1421e-01],\n",
      "        [1.6978e-01, 2.4059e-01, 1.8514e-01, 7.5396e-01]])\n",
      "z1:tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "z2:tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "z3:tensor([[0.6220, 0.2687, 0.6980, 0.9420],\n",
      "        [0.2777, 0.9354, 0.7016, 0.1426],\n",
      "        [0.9863, 0.8366, 0.6872, 0.7848],\n",
      "        [0.3596, 0.7253, 0.9320, 0.6268]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[1., 0., 1., 1.],\n        [1., 0., 1., 1.],\n        [1., 0., 1., 1.],\n        [1., 0., 1., 1.]])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这计算两个张量之间的矩阵乘法。 y1、y2、y3 将具有相同的值\n",
    "# ``tensor.T`` 返回张量的转置\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "y3 = torch.rand_like(y1)\n",
    "print(f\"y1:{y1}\\ny2:{y2}\\ny3:{y3}\")\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "# 这将计算元素乘积。 z1、z2、z3 将具有相同的值\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "z3 = torch.rand_like(tensor)\n",
    "print(f\"z1:{z1}\\nz2:{z2}\\nz3:{z3}\")\n",
    "torch.mul(tensor, tensor, out=z3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T23:18:01.642785Z",
     "end_time": "2023-04-08T23:18:01.724564Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**单元素张量**\n",
    "如果你有一个单元素张量，例如通过将一个张量的所有值相加成一个值，你可以使用 item() 将它转换为 Python 数值。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T23:18:01.659739Z",
     "end_time": "2023-04-08T23:18:01.725586Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**In-place operations**（原地操作，就是在原张量上操作）\n",
    "将结果存储到操作数中的操作称为就地操作。它们由 _ 后缀表示。例如：x.copy_(y),x.t_()，会改变x。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T23:18:01.670711Z",
     "end_time": "2023-04-08T23:18:01.725586Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> note\n",
    "> 就地操作可以节省一些内存，但在计算导数时可能会出现问题，因为会立即丢失原张量信息。因此，不鼓励使用它们。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 桥接 Numpy\n",
    "CPU 上的张量和 NumPy 数组会共享它们的底层内存，改变一个就会改变另一个（可以理解为引用变量，张量和 Numpy 数组都是引用地址）。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 张量转化 Numpy 数组"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T23:18:01.688662Z",
     "end_time": "2023-04-08T23:18:01.725586Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "张量的变化将会引起 Numpy 数组的变化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T23:18:01.703622Z",
     "end_time": "2023-04-08T23:18:01.888106Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Numpy 数组转化张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T23:18:01.717585Z",
     "end_time": "2023-04-08T23:18:01.888106Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Numpy 数组的变化将会引起张量的变化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T23:18:01.733544Z",
     "end_time": "2023-04-08T23:18:01.923049Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
